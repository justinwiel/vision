{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><bold>Eindopdracht voor computer vision, binaire classificatie van hersenscans</bold></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 files belonging to 2 classes.\n",
      "Using 2240 files for training.\n",
      "Found 2800 files belonging to 2 classes.\n",
      "Using 560 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Reshape\n",
    "from keras.datasets import cifar10\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint,seed\n",
    "from time import time_ns\n",
    "\n",
    "data_dir = \"..\\\\data\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=486235864,\n",
    "  image_size=(28, 32),\n",
    "  batch_size=16)\n",
    "images_train = []\n",
    "labels_train = []\n",
    "for images, labels in train_ds:\n",
    "    images_train.append(images)\n",
    "    labels_train.append(labels)\n",
    "\n",
    "vals_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=486235864,\n",
    "  image_size=(28, 32),\n",
    "  batch_size=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.4440 - accuracy: 0.7982 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.2645 - accuracy: 0.8996 - val_loss: 0.2126 - val_accuracy: 0.9321\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.1544 - accuracy: 0.9455 - val_loss: 0.1374 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0735 - accuracy: 0.9759 - val_loss: 0.1974 - val_accuracy: 0.9232\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0791 - accuracy: 0.9732 - val_loss: 0.1193 - val_accuracy: 0.9625\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0574 - accuracy: 0.9777 - val_loss: 0.1241 - val_accuracy: 0.9607\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.1014 - val_accuracy: 0.9643\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 4s 25ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.1163 - val_accuracy: 0.9696\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 4s 27ms/step - loss: 0.0457 - accuracy: 0.9835 - val_loss: 0.0824 - val_accuracy: 0.9786\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 0.0350 - accuracy: 0.9853 - val_loss: 0.2863 - val_accuracy: 0.9107\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 4s 25ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0890 - val_accuracy: 0.9821\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 4s 27ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.0977 - val_accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 4s 27ms/step - loss: 6.0385e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9821\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 2.4181e-04 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9821\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 4s 25ms/step - loss: 1.6306e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9821\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 1.2295e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9821\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 4s 29ms/step - loss: 9.6119e-05 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 4s 29ms/step - loss: 7.8099e-05 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9821\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 4s 29ms/step - loss: 6.5561e-05 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x248fd717850>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=20,validation_data= vals_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 - 1s - loss: 0.1293 - accuracy: 0.9821 - 1s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(vals_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821428656578064\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 files belonging to 2 classes.\n",
      "200/200 - 1s - loss: 0.6706 - accuracy: 0.9350 - 530ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"..\\\\test\"\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=486235864,\n",
    "  image_size=(28, 32),\n",
    "  batch_size=1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350000023841858\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(img,  res):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 3))\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    if(res == 1):\n",
    "        ax.set_title('tumor', fontsize=10)\n",
    "    elif(res == 0):\n",
    "        ax.set_title('healty', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAADQCAYAAABsmA/6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXBklEQVR4nO2deYxU9ZbHv6cRF2RRUBoEFEFEQIWXAQRxG5YJjziAURgQRwbNqPAYBUUkjqMMUaJBVAQ1wKCgwQeCEtDoE1CCg4qyPgQcFtl3FJFFtm7O/FG3teSe01R1df+6Kb6fhHTVt0/f+t1bdbj3njqLqCoIIWHIKe0FEHI2QYcjJCB0OEICQocjJCB0OEICQocjJCB0uDMAEakrIiuLYTv/JiJjosddRaRx5qsj6UCHO3vpCoAOFxg63JlDOREZLyKrRGS2iFwgIvVF5G8iskRE/ldErgEAEflnEflGRJaJyFwRyU3ekIjcCKAzgBEisjzaztKk3zdIfk6KDzrcmUMDAK+pahMA+wHcCWAcgP9Q1X8AMAjA65HtAgCtVPVPAKYAGJy8IVX9CsAsAI+rajNV/QHALyLSLDLpA+Ctkt2ds5NzSnsBJGU2qury6PESAHUB3AhgmogU2JwX/awNYKqI1ARwLoCNKWz/fwD0EZFHAfwLgJbFs2ySDM9wZw7Hkh7nA6gKYH90hir41yj6/WgAY1T1OgAPAjg/he2/D+DPAG4HsERVfyrGtZMIOtyZywEAG0WkGwBIgqbR76oA2B497u38/UEAlQqeqOpRAJ8CeAO8nCwx6HBnNr0A3C8ifwewCkCXSB+KxKXmEgA/On87BcDjUWClfqRNBnASwOySW/LZjbA8hxQgIoMAVFHV/yrttWQrDJoQAICIzABQH0Db0l5LNsMzHCEB4T0cIQGhwxESkIwcTkQ6isgaEVkvIkOKa1GEZCtFvocTkXIA1gLoAGAbgEUAeqrq6kL+JvgNY1IWRqnjHet015jOdrxtp/u+F9fai4N0115cxyAdVNV80UyilC0BrFfVDQAgIlOQ+B7IdTgAKFeuXAYvmT45OWXnqjk/P9/UvWPifVC87ZQvXz6meft/4sQJU/coSw538uRJU/fW6B1f6zgWx/547w+Q2SVlLQBbk55vizRCiEOJfw8nIg8AeKCkX4eQM4FMHG47gDpJz2vj9/y931DVcUiUkZTKPRwhZYlMHG4RgAYiciUSjtYDwN1F2VBp3GcVdp1tce6555q6dd/QqlUr07Z169am3r17d1P/8ssvTb169eqmXqlSpZjWqFEjw9K/Dzp48KCpv/baa6Y+bdq0tLaTTmDHoyQ/L8Wxbe/YAhk4nKrmiUh/JDLMywF4U1VXFXV7hJwNZHQPp6ofA/i4mNZCSNZTdmLmhJwF0OEICQgdjpCAlIl6uLy8vLTsrcyBdCNdVlYGADRo0MDU7733XlP/6ad464+xY8eatps3bzZ1b/9Hjx5t6l27djX19u3bx7S1a9eatjVq1DD1rVu3mvrs2XYRuBftHT58uKkfPnw4po0ZM8a0PXDggKl7pPsZOOec+Me/pMvVeIYjJCB0OEICQocjJCB0OEICQocjJCBBmwiJiFoRRq9eKZ21eRGqSy+91NR79epl6rNmzTL1ffv2mXq3bt1iWr169UzbpUvt+Rh79+419QsvvNDUq1SpYurWMVi2bJlpO378eFMfMsQu3K9YsaKp33TTTaZuRSMB4MUXX4xpTzzxhGnrHZcJEyaY+tGjR03d+2yUVC1fXl4eTp48aW6cZzhCAkKHIyQgdDhCAkKHIyQgQVO7RMQs8POCI55+3nnnxbQmTZqYtgsWLDB1r4gzNzfX1N9//31THzFiREy75JJLTNsLLrjA1L0gSLVq1Uz95ZdfNvX77rsvpnkBqenTp5u6FxypXLmyqTdr1szUX3/9dVO3UsFGjhxp2nrpdzNnzjT1yZMnm7r33h0/fjyl9QHpBfAKs+UZjpCA0OEICQgdjpCA0OEICQgdjpCAZJTaJSKbkJgVnQ8gT1WbF2afk5OjVtGfh7e2hg0bxrS33rLHUnfo0MHU+/XrZ+pexLBx48ambkXjvGik14LNa2W3fXuszScAP13t2LFjMa1NmzamrRel9CKDXhqUVzzr6dYab7/9dtP2888/N/U5c+aYuteyz0sdW7lyZUzzWsCn06L/xIkTbmpXcXwt8I+q6s2RJoQkwUtKQgKSqcMpgNkisiSaIUAIKYRMLylvUtXtIlIdwBwR+T9V/SLZgMM8CPmdjM5wqro9+rkHwAwkZsadajNOVZuravOyNByRkNKgyGc4EbkQQI6qHowe/xOAYUXcVlr6Y489FtNuuOEG07ZHjx6m7kUAV62yxyN4OZlWXqcXXfUGgmzatMnUvby+m2++2dQt1q9fb+resf3ll19M/bLLLjP1PXv2mLp1XAC7Nd3ChQtN25o1a5q6NyyjXbt2pr5//35Tv/HGG2Oa18rQyrsEitCaLy3rP5ILYEb0gucAeFdV/5bB9gjJejKZnrMBQNNiXAshWQ+/FiAkIHQ4QgJChyMkIEHb5Hm5lF5+ZYsWLUx9yZIlMa1t27amrVWRDfgjdL2o3kUXXWTqVms2L6JVtWpVU7fyCwGgeXM7NdUb0PHee+/FtEGDBpm2XpTWi6Tu2LHD1L33zouwWqOIvaijF421oosA8N1335n6O++8Y+pdunSJaaNGjTJtjxw5YupWzijb5BFSRqDDERIQOhwhAaHDERIQOhwhAQk+ctjKPfOqbJ955hlTtyqEp0yZYtoOHDjQ1L0+i9dff72pe+NvV69eHdO8kcBezqC3/ytWrDB1b8jHmjVrYtpzzz1n2nqRwR9/tGuJL774YlO3Ri4DfoV0hQoVYlqtWrVMWy+vcfDgwab+0UcfmbqXH3vXXXfFNK9fqRe9TqcSHOAZjpCg0OEICQgdjpCA0OEICQgdjpCAlIlcyssvv9y096pprbzGBg0amLaHDh0ydW88rRd1Ov/8803dmjbjVZ9v2LDB1L2K5Nq1a5u6l6s5fPjwmOblND7yyCNpveZtt91m6m+//bapW5N8AOCll16KaV6fTa9H6K5du0zd6wfq5V6++uqrMa1z586mrTUqGbBzQ5lLSUgZgQ5HSEDocIQEhA5HSEBO63Ai8qaI7BGRlUlaVRGZIyLrop923g8h5A+kkks5EcAYAMnhqCEAPlPV50VkSPTcHlGSRE5OjpkHOGyY3c7Sy5nz8iMtli1bZupe/qIXMfTsrUrz3r17m7Z33nmnqXt5nV4luBdhtKKXXkW21/PRyxkdN26cqXvbv+aaa0zdqijftm2baXv48GFT92aoexHp2bNnm7qVe+rlUnrbtvbfmxwEpHCGi1qX7ztF7gJgUvR4EoCup9sOIaTo93C5qrozerwLiaawhJDTkHF5jqqqiLjfnicP8+BsAXK2U9Qz3G4RqQkA0U+7wTz+OMzDmwBKyNlCUc9wswD0BvB89HNmKn+Un59vDovw0mkeffRRU587d25M81K7vNQmL7XLCwJ47ePmz58f07wWdKNHjzb1iRMnmrrXVq9GjRqmbqV2DRkyxLT12v55gQpvmIe3HW/IhxWU8gIVXpqdFwjz3rs6deqYunV8+/bta9p6o5i9z5dHKl8L/BXA1wAaisg2EbkfCUfrICLrALSPnhNCTsNpz3Cq2tP5lT0biBDiwpsqQgJChyMkIHQ4QgIStAC1XLlyaqV2jR071rTv16+fqVuRpI0bN5q2XpqNF3XyopHeMAev3ZyFF3XzopFeypfVag4Annginl3njf61IpqAn9rlHcd9+05NQkqQToGvV9zrRUC91nxewarXVvDDDz+MaVu2bDFtvf2x/Of48eMsQCWkLECHIyQgdDhCAkKHIyQgdDhCAhJ0mIeImFGqOXPmmPZexMzKx6tUqZJp6xUOelFHL5LYq1cvU7fGH+/du9e09SJ6Xv6it3Yvl9IqWPUGonhDO7xonFfp4bXs84Z/WJHEH374wbT1ioHr1q1r6l67vXXr1pm6dby84lZvmIfVJtErVgZ4hiMkKHQ4QgJChyMkIHQ4QgJChyMkIEGjlPn5+Wbk0ct184YzPPXUUylpAHD11Veb+qZNm0zdy6VcvHixqVvDHLxIn5czaFXBA/5x+fXXX0195MiRMc2L9KWTAwr4eYoe1nEBgEaNGsU0rzrcy/P13jsvx9I6LgBwxRVXpKQBfjW5VfFdWH4yz3CEBIQOR0hA6HCEBIQOR0hAijrMY6iIbBeR5dG/TiW7TEKyg9NWfIvILQAOAXhbVa+NtKEADqmqPYfVwav4XrRokWlvDcrw9Hvuuce0/fTTT029Xr16pn7VVVeZ+ldffWXqVnPbnTt3GpZ+zmS6Qyu8PMjp06fHtIceesi09SJ6XoW4V/HtVat7OalWf8sBAwaYtt5oYW/8r1ch7kVkJ0yYENO8/FXPT6zo5dGjR4te8e0M8yCEFIFM7uH6i8iK6JKT8+EISYGiOtwbAOoDaAZgJwD7m0UkhnmIyGIRWRyyYREhZZEiOZyq7lbVfFU9CWA8gJaF2P42zIPTc8jZTpEcrmByTsQdAFZ6toSQ3zltLmU0zOM2AJeIyDYAzwC4TUSaAVAAmwA8mMqLnTx50swDnDZtmmnvjdydNWtWTGvSpIlp60XXvMjo5s2bTf3xxx839WeffdbULbxemF6enldNPXToUFOfNGlSTPOmwbzwwgum7h2v+vXrm7oXMc3NtWd0Wnmm/fv3N229iLFXTe5Vgv/888+mbkVM7777btP26aefNvV0p+cUdZhHPJ5KCDktzDQhJCB0OEICQocjJCB0OEICEnR6Tk5OjloV1dWqVTPta9eubepWVG/UqFGmrRfR69Gjh6l7UbcVK1aY+ogRI2KaN5vci9ytXbvW1Bs2bGjqt956q6lbOZlexffKlfY3OV6PyMaNG5u6t/0rr7zS1K+99tqYZs1sB/zqe28tffr0MXUvP/S6666LaV6Oqddr1IrqcnoOIWUEOhwhAaHDERIQOhwhAQnaJg+wiwG9G9KWLe2caGu8cOvWrU1bbwjH1KlTTf2WW24x9Tp16pj65MmTY5qXeuQNhPBas3mpXd9++62pL1u2LKa98sorpq03otkKagB+ylvNmjVN3Wv9ZwXpvKR2L/DitQ/0giNWChdgvx9emp2X8pZu0JFnOEICQocjJCB0OEICQocjJCB0OEICEjxKaUWBvCK+efPmmXqLFi1impfuk247OC+SaL0mACxdujSmecM8vFQlbxSxN7TCG3JiRTUffvhh09aL9HnDT7yoozde1ysGtQqFP/74Y9P2k08+MXUvkuyNHPYiiVZR6ZNPPmnaep9Rrx2gB89whASEDkdIQOhwhASEDkdIQOhwhAQklWEedQC8DSAXibZ441R1lIhUBTAVQF0kWuV1V1W7H9nv21IrSunl0nm6NaDCGmQBAE2bNjV1L7/Oi0bt3r3b1K1onzecI10qVqxo6l7+ojXkZM2aNaatV4Dqjf/1cgy9QRneeGULL9Ln7b+Xq/r111+b+vLly1N+XS9/1Vuj5T+ZFqDmAXhMVRsDaAXgLyLSGMAQAJ+pagMAn0XPCSGFkMr0nJ2qujR6fBDA9wBqAegCoKDz6CQAXUtojYRkDWl98S0idQH8CcA3AHJVtWAQ2i4kLjmtv3kAwAMZrJGQrCHloImIVATwPoABqnog+XeauJA1bwaTh3lktFJCsoCUHE5EyiPhbJNV9YNI3l0w1CP6ad9tE0J+I5UopSBxj7ZPVQck6SMA/KSqz4vIEABVVXVwYdvy2uR5eGuzIkbVq1c3bb2xtatWrTJ1b2iHl2P4/fffxzQv0uXlQHp4I4cHDhxo6jNnzoxpXl6nN0LZiwB6OZNHjhwxde+9s46jF43cunWrqc+fP9/UvTHSXh7o6tWrY1pxjFQrLEqZyj1cGwD/CuA7EVkeaU8CeB7AeyJyP4DNALpnvFJCspxUpucsAOC5fbviXQ4h2Q0zTQgJCB2OkIDQ4QgJSPCK73TwIkZWBMwbT+sNxJgxY4apDxo0yNS9qmRrjW3atDFtvcEXXq6fN7TDyxsdMGBATBs82A4cV6hQwdStkdCFrcXLG/WGomzbti2meXmKXl5rOhFQAJg4caKpF0dEMl14hiMkIHQ4QgJChyMkIHQ4QgJChyMkIGVi5HBx4EWcunbtaupeRXK7dnbyTPfuduaaFRn0IqNebqDXC9PLD/WietYIXSvXE/AjfV4upRd1rFy5sql7leBWlNLrP9qxY0dT/+CDD0zd6zXq5VLm5MTPN+n6g2Wfl5fHkcOElAXocIQEhA5HSEDocIQEhA5HSECC5lKqqpkfZ0WLCsOKSHrRJS8Hslu3bqbev39/U3/33XdN3Yo8er0w+/bta+rPPfecqffs2dPUvcrmAwcOxLRDhw6Ztl6e4oMPPmjqVapUMXUvCtq+fXtTt6K6Xs9PK6IJ+JFRb1a89/myIqnpRinTzcfkGY6QgNDhCAkIHY6QgNDhCAnIaYMmhQzzGArg3wEU3Kk+qap2hOL3baV1k+ndwFo3/N6wCa+gcvLkyabutWzzbtStNKu5c+eato0aNTL1Tp06mbrXVu+LL74w9dzcePNrL23qjjvuMHUvgLFlyxZTX7Bggal77fms4lkvgOMNIimudEQraJJuAC9dUolSFgzzWCoilQAsEZE50e9eVtUXS255hGQXqbTJ2wlgZ/T4oIgUDPMghKRJWufPU4Z5AEB/EVkhIm+KiJlmLiIPiMhiEVkcsjKBkLJIJsM83gBQH0AzJM6AI62/Sx7mURpNWwgpSxR5mIeq7lbVfFU9CWA8gJYlt0xCsoNUopQCYAKA71X1pSS9ZtJ8uDsA2DNsM8A7I5YvXz6mHTt2zLT1opd5eXmm7rWymzVrlqlbETZvbG/nzp1N3SvK7dOnj6lv3LjR1K0Im1eUuXDhQlMfNmyYqXvvxY4dO0zda59nDVHxtu0NRfFuTdJOsyrhiKRFJsM8eopIMyS+KtgEwE7CI4T8RibDPAr9zo0QEoeZJoQEhA5HSEDocIQEJGibPBExX8yLFqVTOOi1jisN0skBBfxIqjfm18v3tIpNvcJRq1gV8KOa3vH1Ioke3jFI5zXLOmyTR0gZgQ5HSEDocIQEhA5HSEDocIQEJHSUci+AzdHTSwDYEyKyC+5n9nG6fb1CVS+1fhHU4f7wwon6uOal8uIB4X5mH5nsKy8pCQkIHY6QgJSmw40rxdcOCfcz+yjyvpbaPRwhZyO8pCQkIMEdTkQ6isgaEVkvIkNCv35JEnUv2yMiK5O0qiIyR0TWRT/tIdpnECJSR0TmichqEVklIo9Eelbtq4icLyLfisjfo/3870i/UkS+iT7DU0Uk5cH1QR1ORMoBeA3AnwE0RqJNQ+OQayhhJgI4dRL8EACfqWoDAJ9Fz890CpoDNwbQCsBfovcx2/b1GIC2qtoUie50HUWkFYAXkGiCfBWAnwHcn+oGQ5/hWgJYr6obVPU4gCkAugReQ4mhql8A2HeK3AXApOjxJABdQ66pJFDVnaq6NHp8EEBBc+Cs2ldNUFDzVD76pwDaAijo2Z7WfoZ2uFoAkicYbkP2d3HOTeputguJGQ1ZwynNgbNuX0WkXNQ8aw+AOQB+ALBfVQvavqX1GWbQJCCaCAlnTVjYaA78G9myr1Hv1WYAaiNxhXZNJtsL7XDbAdRJel470rKZ3SJSE0j08kTif8ozHqs5MLJ0XwFAVfcDmAegNYCLRKSgTD+tz3Boh1sEoEEU5TkXQA8AdofV7GEWgN7R494AZpbiWooFrzkwsmxfReRSEbkoenwBgA5I3K/OA3BXZJbefqpq0H8AOgFYi8S18H+Gfv0S3re/IjFn4QQS1/b3A6iGRMRuHYC5AKqW9jqLYT9vQuJycQWA5dG/Ttm2rwCuB7As2s+VAJ6O9HoAvgWwHsA0AOeluk1mmhASEAZNCAkIHY6QgNDhCAkIHY6QgNDhCAkIHY6QgNDhCAkIHY6QgPw/SQNn7+f4Cp8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.color import rgb2gray\n",
    "spull = test_ds.take(1)\n",
    "images_test = []\n",
    "labels_test = []\n",
    "for images, labels in test_ds:\n",
    "    images_test.append(images)\n",
    "    labels_test.append(labels)\n",
    "#plt.imshow(np.asanyarray(spull))\n",
    "seed(time_ns())\n",
    "test_IM = randint(0,len(images_test))\n",
    "predictions = model.predict(images_test[test_IM])\n",
    "img = images_test[test_IM]\n",
    "img = np.squeeze(rgb2gray(img))\n",
    "\n",
    "res = np.argmax(predictions)\n",
    "show_res(img, res)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from skimage.transform import resize\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import shuffle, seed\n",
    "\n",
    "yespath = '..\\\\data\\\\yes'\n",
    "yesfiles = [f for f in listdir(yespath) if isfile(join(yespath, f))]\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for file in yesfiles:\n",
    "    img = plt.imread(f\"..\\\\data\\\\yes\\\\{file}\")\n",
    "    img = resize(img, (28, 32,3),\n",
    "                 anti_aliasing=True)\n",
    "    x.append(rgb2gray(img).flatten())\n",
    "    y.append('yes')\n",
    "\n",
    "\n",
    "nopath = '..\\\\data\\\\no'\n",
    "nofiles = [f for f in listdir(nopath) if isfile(join(nopath, f))]\n",
    "\n",
    "for file in nofiles:\n",
    "    img = plt.imread(f\"..\\\\data\\\\no\\\\{file}\")\n",
    "    img = resize(img, (28, 32,3),\n",
    "                 anti_aliasing=True)\n",
    "    x.append(rgb2gray(img).flatten())\n",
    "    y.append('no')\n",
    "\n",
    "\n",
    "z = list(zip(x, y))  # zip so it stays together during shuffle\n",
    "seed(7577947579)\n",
    "shuffle(z)\n",
    "\n",
    "x, y = zip(*z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Svm = svm.SVC()\n",
    "Svm.fit(x,y)\n",
    "\n",
    "yespath = '..\\\\test\\\\yes'\n",
    "yesfiles = [f for f in listdir(yespath) if isfile(join(yespath, f))]\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for file in yesfiles:\n",
    "    img = plt.imread(f\"..\\\\test\\\\yes\\\\{file}\")\n",
    "    img = resize(img, (28, 32,3),\n",
    "                 anti_aliasing=True)\n",
    "    x_test.append(rgb2gray(img).flatten())\n",
    "    y_test.append('yes')\n",
    "\n",
    "\n",
    "nopath = '..\\\\test\\\\no'\n",
    "nofiles = [f for f in listdir(nopath) if isfile(join(nopath, f))]\n",
    "\n",
    "for file in nofiles:\n",
    "    img = plt.imread(f\"..\\\\test\\\\no\\\\{file}\")\n",
    "    img = resize(img, (28, 32,3),\n",
    "                 anti_aliasing=True)\n",
    "    x_test.append(rgb2gray(img).flatten())\n",
    "    y_test.append('no')\n",
    "\n",
    "\n",
    "z_test = list(zip(x_test, y_test))  # zip so it stays together during shuffle\n",
    "seed(398475937597439)\n",
    "shuffle(z_test)\n",
    "x_test , y_test = zip(*z_test)\n",
    "\n",
    "evaluation = metrics.accuracy_score(y_test,Svm.predict(x_test))\n",
    "print(evaluation)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bfbb51c095ea4207accf60ac1e0b966bbb6c3d9216577204ab2f0cbe13a26af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
